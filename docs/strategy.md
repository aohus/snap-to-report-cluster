## 사진 성격

- 사진은 "제초, 나무 수술, 토지 공사 과정 사진"이고, 같은 장소의 같은 부분을 공사 전/중/후로 몇 장씩 촬용한 사진임. 같은 부분을 찍은 사진끼리 모으는 것이 목표.
- 야외라 날씨의 영향 있을 수 있음
- 사람이 찍은 사진이라 구조가 완전 동일하지는 않음. 하지만 최대한 같은 장소에서 같은 각도로 찍으려고 노력함.
- "중" 과정에 해당하는 사진은 작업자들 및 크레인 등 도구가 포함되어 있을 가능성 높음.
- gps filtering 거쳐서 10 ~ 30 장의 사진을 받음.
- 같은 구조물이 각각 다른 부분을 찍은 사진에 포함되어 있을 수 있음. (예: 컨테이너 왼쪽, 오른쪽을 찍은 사진에 컨테이너가 포함되어 있을 수 있 서로 다른 부분이니 다른 클러스터임)
- 결과 클러스터는 3장 이상이 되어야함.(희소하게는 2장 포함)

## 전략 요약

“같은 장소 클러스터링”은
① 메타데이터(GPS·시간)로 후보를 좁히고
② 뷰포인트/사람에 강한 이미지 임베딩으로 유사도 계산
③ 로컬 특징 + 기하 검증으로 ‘진짜 같은 장소’만 걸러내고
④ 그 위에서 클러스터링(HDBSCAN/DBSCAN)을 하는 파이프라인으로 가는 게 제일 안정적입니다.

아래에서 단계별 전략이랑 구현 옵션을 쪼개서 정리할게요.

⸻

1. 문제 구조 다시 정의

조건:
• 같은 장소지만:
• 카메라 각도 다름
• 초점 거리 다름 (줌/광각)
• 사람/차/광고판처럼 “일시적 객체”가 가림
• 다른 장소지만:
• 비슷한 패턴(예: 비슷한 건물, 비슷한 카페 인테리어)이 헷갈릴 수 있음

따라서 요구사항: 1. 뷰포인트 변화/가림에 강한 표현 필요 2. ‘장소 자체의 구조’(geometry + layout)에 민감 3. 사람·차 같은 가변 객체에는 둔감

⸻

2. 전체 파이프라인 개요
   1. 전처리 단계 (후보 좁히기)
      • EXIF 기반:
      • GPS가 있으면: 일정 반경(예: 200m 이내)으로 “같은 지역 후보” 필터링
      • 시간이 가까운 것끼리 우선 (여행 동선 기준으로도 후보 제한)
      • GPS가 없으면:
      • 촬영 시각·파일명·폴더 구조로 “여행/세션 단위” 그룹 먼저 묶기
   2. 전역 이미지 임베딩 (viewpoint-robust feature)
      • CNN/ViT 기반 image embedding 사용
      • 목적: 각 사진을 고차원 벡터로 바꿔서 “장소 스타일 + 구조” 유사도를 잡기
      • 사람/차 제거까지 하고 싶다면:
      • 사람/차 detection → 마스크 처리 → 마스크된 이미지를 임베딩에 사용
   3. 로컬 특징 + 기하 검증(geometric verification)
      • SIFT/ORB/SuperPoint 같은 키포인트 + 매칭으로:
      • 같은 장소 후보 쌍에 대해 inlier 매칭 개수 / RANSAC 호모그래피 평가
      • 이걸로:
      • “벡터는 비슷한데 실제 구조가 다른 경우” 제거
      • 예: 비슷한 카페 인테리어지만 실제로는 다른 지점 → 매칭 거의 안 나옴
   4. 유사도 그래프 구성 + 클러스터링
      • 위 정보를 이용해:
      • 노드: 사진
      • 간선 가중치: w1 _ cos_sim(embedding) + w2 _ geo_score + w3 \* meta_score
      • 이 그래프를 기반으로:
      • HDBSCAN, DBSCAN, 또는 연결 요소 분석(connected components) 으로 클러스터링
   5. 후처리
      • 너무 작은 클러스터(예: 1장) → 노이즈로 처리
      • 같은 장소인데 과분할 된 것 → centroid 간 거리/유사도로 병합

⸻

3. 각 단계별 조금 더 구체적인 전략

3-1. 메타데이터로 “가능한 쌍” 줄이기
• GPS 기반 필터링
• 위도/경도 → UTM 혹은 단순 haversine 거리로 계산
• 반경 R (예: 100~300m) 안에 있는 사진들만 “같은 장소 후보”로 저장
• 고도(alt)는 노이즈 크니까, 있어도 가중치 낮게
• 시간 기반
• 같은 날·같은 시간대(±1~2시간)인 사진들을 우선 묶기
• 여행/촬영 세션 단위로 먼저 coarse clustering 하면 전체 계산량 줄어듦

이 단계의 목표는:

O(N²)로 모든 사진 쌍 비교하지 않고,
“공간·시간상 충분히 가까운 쌍”만 다음 단계로 넘기기.

⸻

3-2. 전역 임베딩 선택 전략

요구 조건: viewpoint 변화, 조명, 부분 가림에 꽤 강해야 함.

추천 계열(개념적으로):
• Self-supervised / contrastive ViT 계열 (예: DINO, DINOv2 류)
• 특징: 라벨 없이도 “물체·장면 구조” 잘 잡음
• 장점: 특정 태스크에 오버피팅 덜 되고, 장면 표현에 강함
• CLIP/SigLIP 스타일 멀티모달 모델
• 장점: “텍스트-이미지”로 학습돼서 high-level semantics가 강함
• 단점: “같은 장소지만 구조가 크게 다를 때”는 도움이 되지만,
아주 fine-grained “이 건물 vs 비슷한 다른 건물” 구분은 로컬 특징이 더 좋음

전략: 1. 먼저 전역 임베딩으로 coarse similarity 계산
• 코사인 유사도 기준으로, 일정 threshold 이상인 것만 “같은 장소 후보” 유지 2. 이 단계에서 kNN graph 생성
• 각 이미지에 대해 top-k 유사 이미지(예: k=20)만 유지

실제 구현에서는:
• 임베딩 차원 축소(PCA / UMAP) 필요 시 적용
• approximate nearest neighbor(FAISS, HNSW) 사용해서 속도 확보

⸻

3-3. 로컬 특징 + 기하 검증

문제:
전역 임베딩만 사용하면:
• 비슷한 인테리어/풍경이 다른 장소인데도 붙을 수 있음
• 반대로, 각도 차이가 너무 커도 전역 feature가 떨어질 수 있음

그래서: 1. 후보 쌍에 대해:
• SIFT/SuperPoint 등 로컬 특징 추출
• feature matching (ratio test + cross-check) 2. RANSAC으로 호모그래피/기본행렬 추정
• inlier 매칭 개수, inlier 비율, reprojection error 등을 score 로 활용 3. “기하적으로 일관된 매칭”이 일정 이상이면:
• geo_score = 1에 가까운 값 부여
• 아니면 0에 가깝게

이 geo_score를 그래프의 간선 가중치에 섞으면:
• 같은 장소지만 각도가 다른 사진은 여전히 높은 점수를 갖고
• 다른 장소인데 우연히 비슷한 색/구조인 이미지는 잘 걸러짐

⸻

3-4. 그래프 기반 클러스터링

유사도 정의 예시:

```python
sim(i, j) = α * cos_sim(embedding_i, embedding_j)
          + β * geo_score(i, j)          # RANSAC-based
          + γ * meta_score(i, j)         # 시간/거리 기반
```

    •	meta_score 예:
    •	공간적 거리: exp(-dist_meter / σ_d)
    •	시간 거리: exp(-|t_i - t_j| / σ_t)
    •	α, β, γ는 경험적으로 튜닝 (예: α=0.6, β=0.3, γ=0.1)

이 유사도를 edge weight로 하는 그래프를 만들고:
• threshold 이상인 edge만 남김
• 그 그래프에서:
• 간단히는 연결 요소(connected components)로 클러스터링
• 더 정교하게는 HDBSCAN/DBSCAN을 임베딩 공간에 직접 적용

왜 HDBSCAN 추천?
• 클러스터 수를 미리 지정할 필요 없음
• 밀도 기반이라 “노이즈/애매한 사진”을 자연스럽게 외곽으로 밀어냄

⸻

4. “지나가는 사람” 문제를 더 강하게 해결하는 팁 1. 사람/차 segmentation 후 마스킹
   • 사람/차/동물 영역을 검출(detector or segmenter)해서:
   • 그 부분을 blur or mean color로 채운 이미지로 임베딩 계산
   • 이러면 “장소 구조” 신호가 상대적으로 커짐 2. background-only descriptor
   • 가능하다면:
   • foreground(사람/차) vs background 분리
   • background 영역에 대해서만 feature 추출 3. 데이터 증강으로 viewpoint robustness 강화
   • 만약 자기 데이터로 fine-tune한다면:
   • random crop, perspective transform, color jitter, occlusion augmentation으로
   “각도, 가림 변화에 강한” representation을 학습시킬 수 있음

⸻

5. 관점별 “전략 조합” 3가지 버전

A. 현실적으로 구현 쉬운 버전 (MVP)
• GPS + 시간으로 세션/지역 그룹화
• 공개된 이미지 임베딩 모델(예: CLIP/DINO 계열) 하나로 임베딩
• FAISS로 kNN + 코사인 유사도
• 각 그룹에서 DBSCAN/HDBSCAN 한 번씩 돌려서 클러스터링
• 로컬 특징/기하 검증은 “나중에 정밀도 올릴 때” 추가

장점:
• 구현이 빠르고, 꽤 잘 동작함
단점:
• 비슷한 장소 구분, 가려진 이미지 처리에서 오차가 조금 있음

⸻

B. 정확도 최우선 버전 (연산 많이 써도 됨)
• 메타데이터로 후보 필터링 (GPS, 시간)
• 강력한 ViT 기반 임베딩 + kNN graph
• 후보 쌍에 대해:
• Local feature (SIFT/SuperPoint) + RANSAC
• geo_score 반영
• sim(i, j) = αembedding + βgeo + γ\*meta
• threshold로 edge 걸러낸 뒤, 연결 요소 + HDBSCAN 혼합

장점:
• viewpoint/가림/비슷한 장소 구분까지 높은 수준
단점:
• 계산량과 구현 복잡도 상당히 증가

⸻

C. “온라인 확장” 버전 (새 사진 계속 들어오는 경우)
• 이미 만들어진 클러스터들에 대해: 1. 새 사진 1장을 임베딩 2. 각 클러스터 centroid와 유사도 측정 3. 일정 threshold 이상인 클러스터들만 후보 4. 그 안에서 일부 대표 이미지와 로컬 특징 매칭 → 최종 할당 결정
• threshold 이하이면:
• 새 장소로 새로운 클러스터 생성

⸻

6. 마무리 요약
   • 핵심 아이디어는 3개: 1. 메타데이터로 탐색공간 줄이기 (GPS·시간·폴더 구조) 2. viewpoint-robust 전역 임베딩으로 1차 유사도 계산 3. 로컬 특징 + RANSAC으로 “진짜 같은 장소인지” 기하 검증
   • “최고의 전략”은 이 셋을 결합한 multi-stage 파이프라인이고,
   상황에 따라 (연산·시간·구현 난이도) A/B/C 중 하나로 타협하면 됩니다.
